<TITLE>
Improving Network Durability using Approximate Dynamic Programming
</title>
<H2>
Improving Network Durability using Approximate Dynamic Programming
</H2>


<P>

<B>Download the paper</B>,
in <A HREF=HammelADP.pdf>pdf</A>.

<h3>Authors:</h3>

<b>Erik Hammel</b>
<br>
RankMiner Inc.

<P>

<B><A HREF="http://www.rpi.edu/~mitchj">John E. Mitchell</A></B>
<BR><A HREF="mailto:mitchj@rpi.edu">(email)</A>
<br>
<a href=http://www.rpi.edu/dept/math/>Department of Mathematical Sciences</a>,
<a href=http://www.rpi.edu/>Rensselaer Polytechnic Institute</a>,
Troy, New York 12180-3590, U.S.A.

<p>

<B><a href=http://www.rpi.edu/~sharkt>Thomas C. Sharkey</a></b>
<BR><A HREF="mailto:sharkt@rpi.edu">(email)</A>
<br>
<a href=http://ise.rpi.edu/>Department of Industrial and Systems
Engineering</a>,
<a href=http://www.rpi.edu/>Rensselaer Polytechnic Institute</a>,
Troy, New York 12180-3590, U.S.A.

<p>

<B><A HREF=http://faculty.rpi.edu/node/1050>William A. Wallace</A></B>
<BR><A HREF="mailto:wallaw@rpi.edu">(email)</A>
<br>
<a href=http://ise.rpi.edu/>Department of Industrial and Systems
Engineering</a>,
<a href=http://www.rpi.edu/>Rensselaer Polytechnic Institute</a>,
Troy, New York 12180-3590, U.S.A.



<h3>April 2016</h3>

The material in this paper is based upon work supported by the U.S. Department of Homeland Security under Grant Award Number, 2008-ST-061-ND0001-07. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the U.S. Department of Homeland Security. The work of Thomas C. Sharkey was supported by the U.S. National Science Foundation under CMMI-1254258.

<h3>Abstract:</h3>

Our goal is to optimize the efficacy of reinforcing
an existing flow network to prevent unmet demand from imminent disruptions.
Estimates for the probabilities of failures for edges in the network
are refined as the disaster draws nearer, and
we are asked to find edges which will best provide durability to the
network post-event. The problem is formulated as
an approximate dynamic program (ADP). We derive several innovative adaptations
from reinforcement learning concepts.
We compare the performance of the policy resulting from the ADP
against traditional
two-stage stochastic programs with recourse utilizing a sample average
approximation model.
We provide empirical evidence which corroborates
with basic theorems of convergence for more simplistic forms of the
reinforcement learning process.
The material presented
here is developed in the context of preparing urban infrastructures
against damages caused by disasters, however it is applicable to any
flow network.




<p>
<b>Keywords:</b>
disaster mitigation, infrastructure restoration, approximate dynamic programming



<hr>

<B>Download the paper</B>,
in <A HREF=HammelADP.pdf>pdf</A> |
<a href=../../chrono.html>Return
to my list of papers</a> |
<a href=http://www.rpi.edu/~mitchj>John E. Mitchell</a>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39407322-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</body></html>


